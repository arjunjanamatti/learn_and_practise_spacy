{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.144547Z",
     "start_time": "2020-09-17T16:39:37.536784Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nlp(text) creates a 'Doc' object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.171539Z",
     "start_time": "2020-09-17T16:39:44.145539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = 'It is a random sentence for checking minimum 10 of features of spacy, just to check $5 for currency, aj@gmail.co.in & wwww.aj.com for checking on emails'\n",
    "\n",
    "doc = nlp(text = sample_text)\n",
    "\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inside the 'Doc' object, each of the words are tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.180540Z",
     "start_time": "2020-09-17T16:39:44.173562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.token.Token]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(text) for text in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.192541Z",
     "start_time": "2020-09-17T16:39:44.183538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'nsubj', 'nominal subject'),\n",
       " ('is', 'ROOT', None),\n",
       " ('a', 'det', 'determiner'),\n",
       " ('random', 'amod', 'adjectival modifier'),\n",
       " ('sentence', 'attr', 'attribute'),\n",
       " ('for', 'prep', 'prepositional modifier'),\n",
       " ('checking', 'pcomp', 'complement of preposition'),\n",
       " ('minimum', 'amod', 'adjectival modifier'),\n",
       " ('10', 'dobj', 'direct object'),\n",
       " ('of', 'prep', 'prepositional modifier'),\n",
       " ('features', 'pobj', 'object of preposition'),\n",
       " ('of', 'prep', 'prepositional modifier'),\n",
       " ('spacy', 'pobj', 'object of preposition'),\n",
       " (',', 'punct', 'punctuation'),\n",
       " ('just', 'advmod', 'adverbial modifier'),\n",
       " ('to', 'aux', 'auxiliary'),\n",
       " ('check', 'advcl', 'adverbial clause modifier'),\n",
       " ('$', 'nmod', 'modifier of nominal'),\n",
       " ('5', 'dobj', 'direct object'),\n",
       " ('for', 'prep', 'prepositional modifier'),\n",
       " ('currency', 'pobj', 'object of preposition'),\n",
       " (',', 'punct', 'punctuation'),\n",
       " ('aj@gmail.co.in', 'conj', 'conjunct'),\n",
       " ('&', 'cc', 'coordinating conjunction'),\n",
       " ('wwww.aj.com', 'conj', 'conjunct'),\n",
       " ('for', 'prep', 'prepositional modifier'),\n",
       " ('checking', 'pcomp', 'complement of preposition'),\n",
       " ('on', 'prep', 'prepositional modifier'),\n",
       " ('emails', 'pobj', 'object of preposition')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.text, token.dep_, spacy.explain(token.dep_)) for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if the token is an alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.207539Z",
     "start_time": "2020-09-17T16:39:44.194540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', True),\n",
       " ('is', True),\n",
       " ('a', True),\n",
       " ('random', True),\n",
       " ('sentence', True),\n",
       " ('for', True),\n",
       " ('checking', True),\n",
       " ('minimum', True),\n",
       " ('10', False),\n",
       " ('of', True),\n",
       " ('features', True),\n",
       " ('of', True),\n",
       " ('spacy', True),\n",
       " (',', False),\n",
       " ('just', True),\n",
       " ('to', True),\n",
       " ('check', True),\n",
       " ('$', False),\n",
       " ('5', False),\n",
       " ('for', True),\n",
       " ('currency', True),\n",
       " (',', False),\n",
       " ('aj@gmail.co.in', False),\n",
       " ('&', False),\n",
       " ('wwww.aj.com', False),\n",
       " ('for', True),\n",
       " ('checking', True),\n",
       " ('on', True),\n",
       " ('emails', True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.text, token.is_alpha) for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for currency in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.220538Z",
     "start_time": "2020-09-17T16:39:44.211540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc[index+1] for index, token in enumerate(doc) if token.is_currency]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.232541Z",
     "start_time": "2020-09-17T16:39:44.222541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', True),\n",
       " ('is', True),\n",
       " ('a', True),\n",
       " ('random', False),\n",
       " ('sentence', False),\n",
       " ('for', True),\n",
       " ('checking', False),\n",
       " ('minimum', False),\n",
       " ('10', False),\n",
       " ('of', True),\n",
       " ('features', False),\n",
       " ('of', True),\n",
       " ('spacy', False),\n",
       " (',', False),\n",
       " ('just', True),\n",
       " ('to', True),\n",
       " ('check', False),\n",
       " ('$', False),\n",
       " ('5', False),\n",
       " ('for', True),\n",
       " ('currency', False),\n",
       " (',', False),\n",
       " ('aj@gmail.co.in', False),\n",
       " ('&', False),\n",
       " ('wwww.aj.com', False),\n",
       " ('for', True),\n",
       " ('checking', False),\n",
       " ('on', True),\n",
       " ('emails', False)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.text, token.is_stop) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.248540Z",
     "start_time": "2020-09-17T16:39:44.235541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing the stopwords: \n",
      " It is a random sentence for checking minimum 10 of features of spacy, just to check $5 for currency, aj@gmail.co.in & wwww.aj.com for checking on emails\n",
      "\n",
      "After removing the stopwords: \n",
      " random sentence checking minimum 10 features spacy , check $ 5 currency , aj@gmail.co.in & wwww.aj.com checking emails\n"
     ]
    }
   ],
   "source": [
    "list_without_stopwords = []\n",
    "[list_without_stopwords.append((str(token))) for token in doc if not token.is_stop]\n",
    "print('Before removing the stopwords: \\n', doc)\n",
    "print()\n",
    "print('After removing the stopwords: \\n', [' '.join(list_without_stopwords)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "* Also for normalization or making the words to the root form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.264539Z",
     "start_time": "2020-09-17T16:39:44.251539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It \t\t -PRON-\n",
      "is \t\t be\n",
      "a \t\t a\n",
      "random \t\t random\n",
      "sentence \t\t sentence\n",
      "for \t\t for\n",
      "checking \t\t check\n",
      "minimum \t\t minimum\n",
      "10 \t\t 10\n",
      "of \t\t of\n",
      "features \t\t feature\n",
      "of \t\t of\n",
      "spacy \t\t spacy\n",
      ", \t\t ,\n",
      "just \t\t just\n",
      "to \t\t to\n",
      "check \t\t check\n",
      "$ \t\t $\n",
      "5 \t\t 5\n",
      "for \t\t for\n",
      "currency \t\t currency\n",
      ", \t\t ,\n",
      "aj@gmail.co.in \t\t aj@gmail.co.in\n",
      "& \t\t &\n",
      "wwww.aj.com \t\t wwww.aj.com\n",
      "for \t\t for\n",
      "checking \t\t check\n",
      "on \t\t on\n",
      "emails \t\t email\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, '\\t\\t', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.276543Z",
     "start_time": "2020-09-17T16:39:44.269540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sentence:\n",
      " It is a random sentence for checking minimum 10 of features of spacy, just to check $5 for currency, aj@gmail.co.in & wwww.aj.com for checking on emails\n",
      "\n",
      "Lemmatized or normalized sentence:\n",
      " -PRON- be a random sentence for check minimum 10 of feature of spacy , just to check $ 5 for currency , aj@gmail.co.in & wwww.aj.com for check on email\n"
     ]
    }
   ],
   "source": [
    "try_list = []\n",
    "[try_list.append(str(token.lemma_)) for token in doc]\n",
    "print('Original sentence:\\n', doc)\n",
    "print()\n",
    "print('Lemmatized or normalized sentence:\\n', [' '.join(try_list)][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for emails in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.288542Z",
     "start_time": "2020-09-17T16:39:44.279539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[aj@gmail.co.in]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in doc if token.like_email]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for url in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.299540Z",
     "start_time": "2020-09-17T16:39:44.291554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[wwww.aj.com]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in doc if token.like_url]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:15:13.606182Z",
     "start_time": "2020-09-17T16:15:13.601188Z"
    }
   },
   "source": [
    "### Parts of speech for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.315541Z",
     "start_time": "2020-09-17T16:39:44.301538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRON'),\n",
       " ('is', 'AUX'),\n",
       " ('a', 'DET'),\n",
       " ('random', 'ADJ'),\n",
       " ('sentence', 'NOUN'),\n",
       " ('for', 'ADP'),\n",
       " ('checking', 'VERB'),\n",
       " ('minimum', 'NOUN'),\n",
       " ('10', 'NUM'),\n",
       " ('of', 'ADP'),\n",
       " ('features', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('spacy', 'ADJ'),\n",
       " (',', 'PUNCT'),\n",
       " ('just', 'ADV'),\n",
       " ('to', 'PART'),\n",
       " ('check', 'VERB'),\n",
       " ('$', 'SYM'),\n",
       " ('5', 'NUM'),\n",
       " ('for', 'ADP'),\n",
       " ('currency', 'NOUN'),\n",
       " (',', 'PUNCT'),\n",
       " ('aj@gmail.co.in', 'PROPN'),\n",
       " ('&', 'CCONJ'),\n",
       " ('wwww.aj.com', 'X'),\n",
       " ('for', 'ADP'),\n",
       " ('checking', 'VERB'),\n",
       " ('on', 'ADP'),\n",
       " ('emails', 'NOUN')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.text, token.pos_) for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practise the features of tokens in a PDF document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:44.378568Z",
     "start_time": "2020-09-17T16:39:44.318540Z"
    }
   },
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:45.261756Z",
     "start_time": "2020-09-17T16:39:44.381539Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_text = extract_text('Brochure for Deep Learning and Its Application13.06.2020.pdf')\n",
    "doc = nlp(text = raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for url in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:45.270666Z",
     "start_time": "2020-09-17T16:39:45.263668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[www.nitp.ac.in/ict/,\n",
       " https://forms.gle/zJkAGnega2VajhUF7,\n",
       " www.nitp.ac.in,\n",
       " http://www.nitp.ac.in/ict/]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in doc if token.like_url]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:45.284667Z",
     "start_time": "2020-09-17T16:39:45.272667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mukesh.kumar@nitp.ac.in]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token for token in doc if token.like_email]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:45.300675Z",
     "start_time": "2020-09-17T16:39:45.287668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Rs,\n",
       "  . 500/- \n",
       "    ),\n",
       " (Rs, .  500/-),\n",
       " (Rs,\n",
       "  . 1000/- \n",
       "  )]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(doc[index], doc[index+1: index+4]) for index, token in enumerate(doc) if (str(token) == 'Rs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for dates\n",
    "* This is the not the best method, but with basic knowledge of spacy, we can detect dates, however this data is not so userful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-17T16:39:45.313666Z",
     "start_time": "2020-09-17T16:39:45.303669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2020', 'DATE'),\n",
       " ('1886', 'DATE'),\n",
       " ('1924', 'DATE'),\n",
       " ('One-week', 'DATE'),\n",
       " ('6-8 years', 'DATE'),\n",
       " ('17th to 22nd ,', 'DATE'),\n",
       " ('June', 'DATE'),\n",
       " ('2020', 'DATE'),\n",
       " ('years', 'DATE')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(token.text, token.label_) for token in doc.ents if token.label_ == 'DATE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just with the help of functions available for tokens, we can get the information on the emails, urls, currency with a bit of help very accurately, not a single email or url is missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
