{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparkNLP_basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMktlZwoP/072fEQ20F2EHq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunjanamatti/learn_and_practise_spacy/blob/master/sparkNLP_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIN0-ahVylqn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4cdf3e1e-88ec-4676-a999-8d8c7c079691"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install java\n",
        "! apt-get update -qq\n",
        "! apt-get install -y openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"PATH\"] = os.environ[\"JAVA_HOME\"] + \"/bin:\" + os.environ[\"PATH\"]\n",
        "! java -version\n",
        "\n",
        "# Install pyspark\n",
        "! pip install --ignore-installed -q pyspark==2.4.4\n",
        "! pip install --ignore-installed -q spark-nlp==2.5.4\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openjdk version \"1.8.0_265\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_265-8u265-b01-0ubuntu2~18.04-b01)\n",
            "OpenJDK 64-Bit Server VM (build 25.265-b01, mixed mode)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 70kB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 54.4MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 133kB 3.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JUZwecsP6wE",
        "colab_type": "text"
      },
      "source": [
        "### Start Sparknlp session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhFYulZqyrey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a6a7cef9-c242-4a0f-d1e5-a1ba9fc6169f"
      },
      "source": [
        "import sparknlp\n",
        "\n",
        "spark = sparknlp.start()\n",
        "\n",
        "print('Spark NLP version', sparknlp.version())\n",
        "print()\n",
        "print('Apache spark version', spark.version)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spark NLP version 2.5.4\n",
            "\n",
            "Apache spark version 2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Wea7RYQKT7",
        "colab_type": "text"
      },
      "source": [
        "### Using pre-trained pipelines of SparkNLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_OmF71BPwEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRNpLwDUQUQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_sentences = '''\n",
        "Arjun is currently working in the field of data science.\n",
        "Previously he was working in Gulf and had studied his Masters in USA.\n",
        "He has diverse experiene in oil industry with knowledge of Machine learning, Deep Learning\n",
        "'''\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLJMqtEjQ9II",
        "colab_type": "text"
      },
      "source": [
        "* Explain Document steps\n",
        "  * Document assembler\n",
        "  * Sentence detector\n",
        "  * Tokenizer\n",
        "  * Lemmatizer\n",
        "  * Stemmer\n",
        "  * Part of speech\n",
        "  * Spellcheck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkQCGgSwQvYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "990a3fff-2fa2-4dae-86d2-b523d39bf08a"
      },
      "source": [
        "pipeline = PretrainedPipeline(name = 'explain_document_ml',\n",
        "                              lang = 'en')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "explain_document_ml download started this may take some time.\n",
            "Approx size to download 9.4 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2Ikbt_MQ7h8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca8c109b-257d-4452-8e51-31ac7d97d42c"
      },
      "source": [
        "result = pipeline.annotate(target = sample_sentences)\n",
        "result.keys()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'spell', 'pos', 'lemmas', 'token', 'stems', 'sentence'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6_BBbWeRR1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a3dd9467-e75b-4407-9dcb-0773730dc46b"
      },
      "source": [
        "result['sentence']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Arjun is currently working in the field of data science.',\n",
              " 'Previously he was working in Gulf and had studied his Masters in USA.',\n",
              " 'He has diverse experiene in oil industry with knowledge of Machine learning, Deep Learning']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aALk53oGRfHz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "efee590e-c320-4b23-ee7d-30c35959e408"
      },
      "source": [
        "list(zip(result['token'], result['lemmas'], result['pos']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Arjun', 'Arjun', 'NNP'),\n",
              " ('is', 'be', 'VBZ'),\n",
              " ('currently', 'currently', 'RB'),\n",
              " ('working', 'work', 'VBG'),\n",
              " ('in', 'in', 'IN'),\n",
              " ('the', 'the', 'DT'),\n",
              " ('field', 'field', 'NN'),\n",
              " ('of', 'of', 'IN'),\n",
              " ('data', 'data', 'NNS'),\n",
              " ('science', 'science', 'NN'),\n",
              " ('.', '.', '.'),\n",
              " ('Previously', 'Previously', 'RB'),\n",
              " ('he', 'he', 'PRP'),\n",
              " ('was', 'be', 'VBD'),\n",
              " ('working', 'work', 'VBG'),\n",
              " ('in', 'in', 'IN'),\n",
              " ('Gulf', 'Gulf', 'NNP'),\n",
              " ('and', 'and', 'CC'),\n",
              " ('had', 'have', 'VBD'),\n",
              " ('studied', 'study', 'VBN'),\n",
              " ('his', 'he', 'PRP$'),\n",
              " ('Masters', 'Masters', 'NNP'),\n",
              " ('in', 'in', 'IN'),\n",
              " ('USA', 'USA', 'NNP'),\n",
              " ('.', '.', '.'),\n",
              " ('He', 'He', 'PRP'),\n",
              " ('has', 'have', 'VBZ'),\n",
              " ('diverse', 'diverse', 'JJ'),\n",
              " ('experiene', 'experience', 'NN'),\n",
              " ('in', 'in', 'IN'),\n",
              " ('oil', 'oil', 'NN'),\n",
              " ('industry', 'industry', 'NN'),\n",
              " ('with', 'with', 'IN'),\n",
              " ('knowledge', 'knowledge', 'NN'),\n",
              " ('of', 'of', 'IN'),\n",
              " ('Machine', 'Machine', 'NNP'),\n",
              " ('learning', 'learn', 'VBG'),\n",
              " (',', ',', ','),\n",
              " ('Deep', 'Deep', 'JJ'),\n",
              " ('Learning', 'Learning', 'NNP')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlMZHpUTR4Ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP1QjhyvSTM-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bdc4b8b5-0d7b-49aa-8bc0-303f73d47f9d"
      },
      "source": [
        "pd.DataFrame(data = {'token': result['token'],\n",
        "                     'pos': result['pos'],\n",
        "                     'lemmas': result['lemmas']})"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>pos</th>\n",
              "      <th>lemmas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arjun</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Arjun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>currently</td>\n",
              "      <td>RB</td>\n",
              "      <td>currently</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>working</td>\n",
              "      <td>VBG</td>\n",
              "      <td>work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>field</td>\n",
              "      <td>NN</td>\n",
              "      <td>field</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>data</td>\n",
              "      <td>NNS</td>\n",
              "      <td>data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>science</td>\n",
              "      <td>NN</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Previously</td>\n",
              "      <td>RB</td>\n",
              "      <td>Previously</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>he</td>\n",
              "      <td>PRP</td>\n",
              "      <td>he</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>was</td>\n",
              "      <td>VBD</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>working</td>\n",
              "      <td>VBG</td>\n",
              "      <td>work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Gulf</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Gulf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>and</td>\n",
              "      <td>CC</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>had</td>\n",
              "      <td>VBD</td>\n",
              "      <td>have</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>studied</td>\n",
              "      <td>VBN</td>\n",
              "      <td>study</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>his</td>\n",
              "      <td>PRP$</td>\n",
              "      <td>he</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Masters</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Masters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>USA</td>\n",
              "      <td>NNP</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>He</td>\n",
              "      <td>PRP</td>\n",
              "      <td>He</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>has</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>have</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>diverse</td>\n",
              "      <td>JJ</td>\n",
              "      <td>diverse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>experiene</td>\n",
              "      <td>NN</td>\n",
              "      <td>experience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>in</td>\n",
              "      <td>IN</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>oil</td>\n",
              "      <td>NN</td>\n",
              "      <td>oil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>industry</td>\n",
              "      <td>NN</td>\n",
              "      <td>industry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>with</td>\n",
              "      <td>IN</td>\n",
              "      <td>with</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>knowledge</td>\n",
              "      <td>NN</td>\n",
              "      <td>knowledge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Machine</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Machine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>learning</td>\n",
              "      <td>VBG</td>\n",
              "      <td>learn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Deep</td>\n",
              "      <td>JJ</td>\n",
              "      <td>Deep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Learning</td>\n",
              "      <td>NNP</td>\n",
              "      <td>Learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         token   pos      lemmas\n",
              "0        Arjun   NNP       Arjun\n",
              "1           is   VBZ          be\n",
              "2    currently    RB   currently\n",
              "3      working   VBG        work\n",
              "4           in    IN          in\n",
              "5          the    DT         the\n",
              "6        field    NN       field\n",
              "7           of    IN          of\n",
              "8         data   NNS        data\n",
              "9      science    NN     science\n",
              "10           .     .           .\n",
              "11  Previously    RB  Previously\n",
              "12          he   PRP          he\n",
              "13         was   VBD          be\n",
              "14     working   VBG        work\n",
              "15          in    IN          in\n",
              "16        Gulf   NNP        Gulf\n",
              "17         and    CC         and\n",
              "18         had   VBD        have\n",
              "19     studied   VBN       study\n",
              "20         his  PRP$          he\n",
              "21     Masters   NNP     Masters\n",
              "22          in    IN          in\n",
              "23         USA   NNP         USA\n",
              "24           .     .           .\n",
              "25          He   PRP          He\n",
              "26         has   VBZ        have\n",
              "27     diverse    JJ     diverse\n",
              "28   experiene    NN  experience\n",
              "29          in    IN          in\n",
              "30         oil    NN         oil\n",
              "31    industry    NN    industry\n",
              "32        with    IN        with\n",
              "33   knowledge    NN   knowledge\n",
              "34          of    IN          of\n",
              "35     Machine   NNP     Machine\n",
              "36    learning   VBG       learn\n",
              "37           ,     ,           ,\n",
              "38        Deep    JJ        Deep\n",
              "39    Learning   NNP    Learning"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MwpLCsV2YN-y"
      },
      "source": [
        "* Explain Document in Deep Learning steps\n",
        "  * Document assembler\n",
        "  * Sentence detector\n",
        "  * Tokenizer\n",
        "  * NER (Named Entity Recognition with GLoVe 100D embeddings, CoNLL2003 dataset)\n",
        "  * Lemmatizer\n",
        "  * Stemmer\n",
        "  * Part of speech\n",
        "  * Spellcheck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOf_miUfTCmM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "05f70808-aa9d-4cf5-8092-092d1c6b0651"
      },
      "source": [
        "pipeline_dl = PretrainedPipeline(name = 'explain_document_dl',\n",
        "                                 lang = 'en')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "explain_document_dl download started this may take some time.\n",
            "Approx size to download 168.4 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UV3fbn0QZBPk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ded0bd3c-8642-4cf7-cdaa-bec3549b3580"
      },
      "source": [
        "result_dl = pipeline_dl.annotate(target = sample_sentences)\n",
        "result_dl.keys()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['entities', 'stem', 'checked', 'lemma', 'document', 'pos', 'token', 'ner', 'embeddings', 'sentence'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiZKui75ZN91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef0c0cce-38f7-42ff-991d-d892a1724d67"
      },
      "source": [
        "result_dl['entities']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Arjun', 'Gulf', 'Masters', 'USA', 'Machine', 'Deep Learning']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTuUiW1TZW2o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3e6262d-2376-410a-ee86-dedcd1b54935"
      },
      "source": [
        "pd.DataFrame(data = {'token': result_dl['token'],\n",
        "                     'ner': result_dl['ner'],\n",
        "                     'embeddings': result_dl['embeddings']})"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>ner</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arjun</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>Arjun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is</td>\n",
              "      <td>O</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>currently</td>\n",
              "      <td>O</td>\n",
              "      <td>currently</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>working</td>\n",
              "      <td>O</td>\n",
              "      <td>working</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>field</td>\n",
              "      <td>O</td>\n",
              "      <td>field</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>data</td>\n",
              "      <td>O</td>\n",
              "      <td>data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>science</td>\n",
              "      <td>O</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Previously</td>\n",
              "      <td>O</td>\n",
              "      <td>Previously</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>he</td>\n",
              "      <td>O</td>\n",
              "      <td>he</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>was</td>\n",
              "      <td>O</td>\n",
              "      <td>was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>working</td>\n",
              "      <td>O</td>\n",
              "      <td>working</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Gulf</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>Gulf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>had</td>\n",
              "      <td>O</td>\n",
              "      <td>had</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>studied</td>\n",
              "      <td>O</td>\n",
              "      <td>studied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>his</td>\n",
              "      <td>O</td>\n",
              "      <td>his</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Masters</td>\n",
              "      <td>B-MISC</td>\n",
              "      <td>Masters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>USA</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>He</td>\n",
              "      <td>O</td>\n",
              "      <td>He</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>has</td>\n",
              "      <td>O</td>\n",
              "      <td>has</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>diverse</td>\n",
              "      <td>O</td>\n",
              "      <td>diverse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>experiene</td>\n",
              "      <td>O</td>\n",
              "      <td>experiene</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>oil</td>\n",
              "      <td>O</td>\n",
              "      <td>oil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>industry</td>\n",
              "      <td>O</td>\n",
              "      <td>industry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>with</td>\n",
              "      <td>O</td>\n",
              "      <td>with</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>knowledge</td>\n",
              "      <td>O</td>\n",
              "      <td>knowledge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Machine</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>Machine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>learning</td>\n",
              "      <td>O</td>\n",
              "      <td>learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Deep</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>Deep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Learning</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>Learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         token     ner  embeddings\n",
              "0        Arjun   B-PER       Arjun\n",
              "1           is       O          is\n",
              "2    currently       O   currently\n",
              "3      working       O     working\n",
              "4           in       O          in\n",
              "5          the       O         the\n",
              "6        field       O       field\n",
              "7           of       O          of\n",
              "8         data       O        data\n",
              "9      science       O     science\n",
              "10           .       O           .\n",
              "11  Previously       O  Previously\n",
              "12          he       O          he\n",
              "13         was       O         was\n",
              "14     working       O     working\n",
              "15          in       O          in\n",
              "16        Gulf   B-LOC        Gulf\n",
              "17         and       O         and\n",
              "18         had       O         had\n",
              "19     studied       O     studied\n",
              "20         his       O         his\n",
              "21     Masters  B-MISC     Masters\n",
              "22          in       O          in\n",
              "23         USA   B-LOC         USA\n",
              "24           .       O           .\n",
              "25          He       O          He\n",
              "26         has       O         has\n",
              "27     diverse       O     diverse\n",
              "28   experiene       O   experiene\n",
              "29          in       O          in\n",
              "30         oil       O         oil\n",
              "31    industry       O    industry\n",
              "32        with       O        with\n",
              "33   knowledge       O   knowledge\n",
              "34          of       O          of\n",
              "35     Machine   B-ORG     Machine\n",
              "36    learning       O    learning\n",
              "37           ,       O           ,\n",
              "38        Deep   B-ORG        Deep\n",
              "39    Learning   I-ORG    Learning"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hOKYw8Qc-ZA",
        "colab_type": "text"
      },
      "source": [
        "### Recognize entities DL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJMdwufnZh98",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "2564ed9c-1b8d-4a19-d6bc-7f3a36cf3007"
      },
      "source": [
        "recognize_entities_pipeline = PretrainedPipeline(name = 'recognize_entities_dl',\n",
        "                                                lang = 'en')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recognize_entities_dl download started this may take some time.\n",
            "Approx size to download 159 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDgE8J65dN4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f62a68a4-7f28-4aff-d897-2081fe537cf9"
      },
      "source": [
        "result_recognize_entities = recognize_entities_pipeline.annotate(target = sample_sentences)\n",
        "result_recognize_entities.keys()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['entities', 'document', 'token', 'ner', 'embeddings', 'sentence'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJtxIi4vdahS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57f17441-7b52-4ad7-978a-a07bea03d4f7"
      },
      "source": [
        "result_recognize_entities['entities']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Arjun', 'Gulf', 'Masters', 'USA', 'Machine', 'Deep Learning']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-p1OElfdeq2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4ca9ad0d-fada-4f37-d7c8-f216a6b33b98"
      },
      "source": [
        "pd.DataFrame(data = {'token': result_recognize_entities['token'],\n",
        "                     'ner': result_recognize_entities['ner'],\n",
        "                     'embeddings': result_recognize_entities['embeddings']})"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>ner</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arjun</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>Arjun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is</td>\n",
              "      <td>O</td>\n",
              "      <td>is</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>currently</td>\n",
              "      <td>O</td>\n",
              "      <td>currently</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>working</td>\n",
              "      <td>O</td>\n",
              "      <td>working</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>field</td>\n",
              "      <td>O</td>\n",
              "      <td>field</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>data</td>\n",
              "      <td>O</td>\n",
              "      <td>data</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>science</td>\n",
              "      <td>O</td>\n",
              "      <td>science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Previously</td>\n",
              "      <td>O</td>\n",
              "      <td>Previously</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>he</td>\n",
              "      <td>O</td>\n",
              "      <td>he</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>was</td>\n",
              "      <td>O</td>\n",
              "      <td>was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>working</td>\n",
              "      <td>O</td>\n",
              "      <td>working</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Gulf</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>Gulf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>had</td>\n",
              "      <td>O</td>\n",
              "      <td>had</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>studied</td>\n",
              "      <td>O</td>\n",
              "      <td>studied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>his</td>\n",
              "      <td>O</td>\n",
              "      <td>his</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Masters</td>\n",
              "      <td>B-MISC</td>\n",
              "      <td>Masters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>USA</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>USA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>He</td>\n",
              "      <td>O</td>\n",
              "      <td>He</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>has</td>\n",
              "      <td>O</td>\n",
              "      <td>has</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>diverse</td>\n",
              "      <td>O</td>\n",
              "      <td>diverse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>experiene</td>\n",
              "      <td>O</td>\n",
              "      <td>experiene</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>oil</td>\n",
              "      <td>O</td>\n",
              "      <td>oil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>industry</td>\n",
              "      <td>O</td>\n",
              "      <td>industry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>with</td>\n",
              "      <td>O</td>\n",
              "      <td>with</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>knowledge</td>\n",
              "      <td>O</td>\n",
              "      <td>knowledge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Machine</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>Machine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>learning</td>\n",
              "      <td>O</td>\n",
              "      <td>learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Deep</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>Deep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Learning</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>Learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         token     ner  embeddings\n",
              "0        Arjun   B-PER       Arjun\n",
              "1           is       O          is\n",
              "2    currently       O   currently\n",
              "3      working       O     working\n",
              "4           in       O          in\n",
              "5          the       O         the\n",
              "6        field       O       field\n",
              "7           of       O          of\n",
              "8         data       O        data\n",
              "9      science       O     science\n",
              "10           .       O           .\n",
              "11  Previously       O  Previously\n",
              "12          he       O          he\n",
              "13         was       O         was\n",
              "14     working       O     working\n",
              "15          in       O          in\n",
              "16        Gulf   B-LOC        Gulf\n",
              "17         and       O         and\n",
              "18         had       O         had\n",
              "19     studied       O     studied\n",
              "20         his       O         his\n",
              "21     Masters  B-MISC     Masters\n",
              "22          in       O          in\n",
              "23         USA   B-LOC         USA\n",
              "24           .       O           .\n",
              "25          He       O          He\n",
              "26         has       O         has\n",
              "27     diverse       O     diverse\n",
              "28   experiene       O   experiene\n",
              "29          in       O          in\n",
              "30         oil       O         oil\n",
              "31    industry       O    industry\n",
              "32        with       O        with\n",
              "33   knowledge       O   knowledge\n",
              "34          of       O          of\n",
              "35     Machine   B-ORG     Machine\n",
              "36    learning       O    learning\n",
              "37           ,       O           ,\n",
              "38        Deep   B-ORG        Deep\n",
              "39    Learning   I-ORG    Learning"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ifZo3wfdy2A",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "how7O6PUdlEH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d8f26d1c-f414-4a4b-cd23-df8c65a94e25"
      },
      "source": [
        "clean_stop_words_pipeline = PretrainedPipeline(name = 'clean_stop',\n",
        "                                               lang = 'en')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_stop download started this may take some time.\n",
            "Approx size to download 12.4 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAahkjtFexKQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e691c73-ef50-42ec-e94e-59c3c9a55cd0"
      },
      "source": [
        "result_stop_words = clean_stop_words_pipeline.annotate(target = sample_sentences)\n",
        "result_stop_words.keys()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'sentence', 'token', 'cleanTokens'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNMeMF09e4Rx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "67dc2a6b-676a-4c1c-dd4b-e01dff3f36a0"
      },
      "source": [
        "print('Original sentence: \\n', result_stop_words['sentence'])\n",
        "print()\n",
        "cleaned_sentence = [' '.join(result_stop_words['cleanTokens'])]\n",
        "print('Cleaned sentence: \\n', cleaned_sentence)\n",
        "print()\n",
        "print('Stop Words in the sample sentence: ')\n",
        "[words for words in result_stop_words['token'] if words not in result_stop_words['cleanTokens']]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence: \n",
            " ['Arjun is currently working in the field of data science.', 'Previously he was working in Gulf and had studied his Masters in USA.', 'He has diverse experiene in oil industry with knowledge of Machine learning, Deep Learning']\n",
            "\n",
            "Cleaned sentence: \n",
            " ['Arjun currently working field data science . Previously working Gulf studied Masters USA . diverse experiene oil industry knowledge Machine learning , Deep Learning']\n",
            "\n",
            "Stop Words in the sample sentence: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is',\n",
              " 'in',\n",
              " 'the',\n",
              " 'of',\n",
              " 'he',\n",
              " 'was',\n",
              " 'in',\n",
              " 'and',\n",
              " 'had',\n",
              " 'his',\n",
              " 'in',\n",
              " 'He',\n",
              " 'has',\n",
              " 'in',\n",
              " 'with',\n",
              " 'of']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92mJambglq1",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning Slang"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG-fTeuXe7WI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3f940601-2209-416e-c4e2-7c79368cf3f7"
      },
      "source": [
        "clean_slang = PretrainedPipeline(name = 'clean_slang',\n",
        "                                 lang = 'en')\n",
        "\n",
        "result_clean_slang = clean_slang.annotate('Yo baby, call me ASAP')\n",
        "result_clean_slang.keys()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean_slang download started this may take some time.\n",
            "Approx size to download 21.8 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'token', 'normal'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y746bSD5g8aX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3db90e8b-7fd6-4573-f597-8102ff1500cf"
      },
      "source": [
        "result_clean_slang['normal']"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hey', 'baby', 'call', 'me', 'as', 'soon', 'as', 'possible']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njZGkhkghAPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e305de00-c9fc-44bc-d97f-9e4b5e4eb229"
      },
      "source": [
        "[' '.join(result_clean_slang['normal'])]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hey baby call me as soon as possible']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjG8ocRjh9RH",
        "colab_type": "text"
      },
      "source": [
        "### Spell Checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxPEUzDRhbqq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5c4ba07a-1978-43dd-a4d2-2fef0b47b325"
      },
      "source": [
        "spell_checker_pipeline = PretrainedPipeline(name = 'check_spelling',\n",
        "                                            lang = 'en')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check_spelling download started this may take some time.\n",
            "Approx size to download 892.6 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrAhgxzqiHMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_sentence_check_spelling = 'I em goong to perty tonight'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ut-0lBNiPsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d51ccb3b-2ae1-4956-b6c1-e410c5580a09"
      },
      "source": [
        "result_spell_check = spell_checker_pipeline.annotate(target = sample_sentence_check_spelling)\n",
        "result_spell_check.keys()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'sentence', 'token', 'checked'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhFDaxuMibdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b67a43e2-b352-4621-cbf2-32ba1b3b91c3"
      },
      "source": [
        "print('Original sentence: \\n', sample_sentence_check_spelling)\n",
        "print()\n",
        "corrected = [' '.join(result_spell_check['checked'])]\n",
        "print('Spell corrected sentence: \\n', corrected)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence: \n",
            " I em goong to perty tonight\n",
            "\n",
            "Spell corrected sentence: \n",
            " ['I em gon to party tonight']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG472ZVyi0GH",
        "colab_type": "text"
      },
      "source": [
        "* In the above sentence, em is not changed to am, goong is not changed to going"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACcDLYRLi7fm",
        "colab_type": "text"
      },
      "source": [
        "### Spell Checker DL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyBftj2aiexY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "3cf6e296-cac4-4f2f-ddd7-4fd1e143a61c"
      },
      "source": [
        "spell_checker_pipeline_dl = PretrainedPipeline(name = 'check_spelling_dl',\n",
        "                                               lang = 'en')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check_spelling_dl download started this may take some time.\n",
            "Approx size to download 112.1 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LihLetOjjek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71d95fb3-95a6-491f-fc42-d9a273d11e8b"
      },
      "source": [
        "result_spell_check_dl = spell_checker_pipeline_dl.annotate(target = sample_sentence_check_spelling)\n",
        "result_spell_check_dl.keys()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'sentence', 'token', 'checked'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZebjBk7vj3q-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "32bf87d1-8c38-47ff-ff90-cbc8783eb3a5"
      },
      "source": [
        "print('Original sentence: \\n', sample_sentence_check_spelling)\n",
        "print()\n",
        "corrected = [' '.join(result_spell_check_dl['checked'])]\n",
        "print('Spell corrected sentence: \\n', corrected)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence: \n",
            " I em goong to perty tonight\n",
            "\n",
            "Spell corrected sentence: \n",
            " ['I me going to Berty tonight']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpixXN-Smj2T",
        "colab_type": "text"
      },
      "source": [
        "### Pipeline for lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZUShqCmj7-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_sentences_list = ['Arjun is currently working in the field of data science.',\n",
        "'Previously he was working in Gulf and had studied his Masters in USA.',\n",
        "'He has diverse experiene in oil industry with knowledge of Machine learning, Deep Learning']\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv4BqArtuQYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e942c483-ac01-47b1-dee5-e7ee5f84c6a3"
      },
      "source": [
        "pipeline = PretrainedPipeline(name = 'explain_document_ml',\n",
        "                              lang = 'en')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "explain_document_ml download started this may take some time.\n",
            "Approx size to download 9.4 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiSKNV5zuY96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "27ca0aca-1ed4-4315-cb4a-a80a552ce3d0"
      },
      "source": [
        "result = pipeline.annotate(target = sample_sentences_list)\n",
        "print('Original sentence: \\n', result[1]['document'])\n",
        "print()\n",
        "print('Lemma or normalized words: \\n', [' '.join(result[1]['lemmas'])])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original sentence: \n",
            " ['Previously he was working in Gulf and had studied his Masters in USA.']\n",
            "\n",
            "Lemma or normalized words: \n",
            " ['Previously he be work in Gulf and have study he Masters in USA .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R09VRp_avvpC",
        "colab_type": "text"
      },
      "source": [
        "### Using fullAnnotate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T7jTl18udPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_text = 'Peter Parker is a nice guy and lives in New York'"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyNct3SUv430",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detailed_result = pipeline_dl.fullAnnotate(target = sample_text)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUQ1WiZYwGMv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1091aa37-9ba0-41db-b40b-ff28a48cd9cf"
      },
      "source": [
        "detailed_result[0]['entities']"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Annotation(chunk, 0, 11, Peter Parker, {'entity': 'PER', 'sentence': '0', 'chunk': '0'}),\n",
              " Annotation(chunk, 40, 47, New York, {'entity': 'LOC', 'sentence': '0', 'chunk': '1'})]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyX9n5_6x2qm",
        "colab_type": "text"
      },
      "source": [
        "### Use pre-trained match_chunk Pipeline for Individual Noun Phrase\n",
        "* Stages\n",
        "  * Document Assembler\n",
        "  * Sentence Detector\n",
        "  * Tokenizer\n",
        "  * Part of speech\n",
        "  * Chunker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsTE1AYCwJ6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "14a4f8a1-636e-46f2-edcf-8618e3bbd9b6"
      },
      "source": [
        "pipeline_chunk = PretrainedPipeline(name = 'match_chunks',\n",
        "                                    lang = 'en')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "match_chunks download started this may take some time.\n",
            "Approx size to download 4.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDtq0Hzzzcla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "572dfee7-c743-49a4-bec0-c1e89225d183"
      },
      "source": [
        "sample_text_for_chunk = 'This book has many chapters'\n",
        "\n",
        "result_chunk = pipeline_chunk.annotate(target = sample_text_for_chunk)\n",
        "result_chunk.keys()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['chunk', 'document', 'pos', 'token', 'sentence'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Lo3lJI0PCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9608e12-bcca-4351-91b9-b45cdaee73c9"
      },
      "source": [
        "result_chunk['chunk']"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This book']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhnPrksM-FVU",
        "colab_type": "text"
      },
      "source": [
        "### Extract dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gl4Nxim0Rns",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4f4d2c51-efcb-4122-d892-bc3dece769b9"
      },
      "source": [
        "pipeline_dates = PretrainedPipeline(name = 'match_datetime',\n",
        "                                    lang = 'en')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "match_datetime download started this may take some time.\n",
            "Approx size to download 12.9 KB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7zFu9Ih-YFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_text_dates = 'I have a flight on 20th June'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7d86JcT_HLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "965d7055-d1f2-431c-e66d-0f26f9f62958"
      },
      "source": [
        "result_dates = pipeline_dates.annotate(target = sample_text_dates)\n",
        "result_dates"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date': ['2020/06/20'],\n",
              " 'document': ['I have a flight on 20th June'],\n",
              " 'sentence': ['I have a flight on 20th June'],\n",
              " 'token': ['I', 'have', 'a', 'flight', 'on', '20th', 'June']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryoxhOjY_aUc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f9df712-0df4-400c-a0bb-76ee32f19d8b"
      },
      "source": [
        "result_dates['date']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2020/06/20']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfIkLvpsA2Cc",
        "colab_type": "text"
      },
      "source": [
        "### Sentiment Analysis\n",
        "\n",
        "#### Vivek algo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQSNyk2u_3eI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0d4d697c-088b-4924-8e37-d43f3fd0a6cd"
      },
      "source": [
        "sentiment = PretrainedPipeline(name = 'analyze_sentiment',\n",
        "                               lang = 'en')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentiment download started this may take some time.\n",
            "Approx size to download 4.9 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6SDm28qB1b-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe2399de-f204-4912-d784-a6ee6663cd91"
      },
      "source": [
        "result_sentiment = sentiment.annotate(target = 'The movie watched was not that good')\n",
        "result_sentiment['sentiment']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKZcDCLRCKhF",
        "colab_type": "text"
      },
      "source": [
        "#### DL version (trained on imbd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWfKEpsdCGus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a467c577-e712-4e15-ea84-e68745028624"
      },
      "source": [
        "sentiment_imbd = PretrainedPipeline(name = 'analyze_sentimentdl_use_imdb',\n",
        "                                    lang = 'en')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentimentdl_use_imdb download started this may take some time.\n",
            "Approx size to download 935.8 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySkZjxVnCi17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "557eef6d-56ad-45e3-d91f-0fd5f796c3af"
      },
      "source": [
        "comment = '''\n",
        "It's a very scary film but what impressed me was how true the film sticks to the original's tricks; it isn't filled with loud in-your-face jump scares, in fact, a lot of what makes this film scary is the slick cinematography and intricate shadow play. The use of lighting and creation of atmosphere is what makes this film so tense, which is why it's perfectly suited for those who like Horror movies but without the obnoxious gore.\n",
        "'''\n",
        "result_sentiment_imdb = sentiment_imbd.annotate(target = comment)\n",
        "\n",
        "result_sentiment_imdb.keys()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['document', 'sentence_embeddings', 'sentiment'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8YH8OzyDxp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10f0cce3-bf7b-4ddf-9d21-9555420d792a"
      },
      "source": [
        "result_sentiment_imdb['sentiment']"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE60SuDbELEC",
        "colab_type": "text"
      },
      "source": [
        "#### DL version (trained on twitter dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDSWpZWvD9hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "272968ae-593f-43b7-e2b8-93d94f7f09da"
      },
      "source": [
        "sentiment_twitter = PretrainedPipeline(name = 'analyze_sentimentdl_use_twitter',\n",
        "                                       lang = 'en')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "analyze_sentimentdl_use_twitter download started this may take some time.\n",
            "Approx size to download 928.3 MB\n",
            "[OK!]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NprFwRhREfgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c586d9e-87ef-4327-dbe6-47811499fab6"
      },
      "source": [
        "result_sentiment_twitter = sentiment_twitter.annotate(target = 'The movie watched was not that good')\n",
        "result_sentiment_twitter['sentiment']"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChKeWxH_EoaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}